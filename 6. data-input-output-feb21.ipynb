{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, we have primarily entered the information into our various data structures manually. For most applications, we will load our data into an appropriate data structure, and potentially output our processed and/or analyzed data using one of potentially many approaches. We have already encountered the following methods that facilitate saving and loading data:\n",
    "\n",
    "* %pwd, %ls, %cd magic commands\n",
    "* !pwd, !ls, !cd shell commands\n",
    "* os module\n",
    "* %store magic command\n",
    "* NumPy save/savetxt and load/loadtxt/genfromtxt\n",
    "\n",
    "Today, we will explore several other methods:\n",
    "\n",
    "* glob module\n",
    "* Standard file input and output\n",
    "* csv reader\n",
    "* pickle and shelve modules\n",
    "* pandas methods\n",
    "\n",
    "In addition to today's topics, you may also want to explore Python's capability for interacting with other data types:\n",
    "\n",
    "* json module (JSON)\n",
    "* lxml (XML)\n",
    "* requests, urllib2 modules (HTML)\n",
    "* BeautifulSoup (HTML)\n",
    "* Excel files (pd.read_excel)\n",
    "* Database methods (sqlalchemy, pd.read_sql, sqlite3)\n",
    "* Web application programming interface (API) methods\n",
    "\n",
    "Friendly Reminders:\n",
    "\n",
    "* Homework #2 due tonight by 11:59 p.m.\n",
    "* Homework #3 released today, due March 5 by 11:59 p.m.\n",
    "* Project proposal due March 7 by 11:59 p.m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## glob Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **glob** module allows you to determine all of the file names on a particular path that match a particular pattern. The glob module offers two functions:\n",
    "\n",
    "* glob.glob(*pattern*) returns a list of file names that match *pattern*\n",
    "* glob.iglob(*pattern*) performs the same operation, but returns an iterator object instead (useful for many files)\n",
    "\n",
    "The pattern may consist of explicit characters for the directory path and file names, but also any combination of the following Unix-based special characters:\n",
    "\n",
    "* The asterisk ('*') matches text of any length\n",
    "* The question mark ('?') matches any single character\n",
    "* '[set]' matches any characters in the set\n",
    "* '[!set]' matches any characters not in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weiyaoma/Desktop/Xjpynb/Data Files\n"
     ]
    }
   ],
   "source": [
    "# Change current working directory to data folder\n",
    "%cd '/Users/weiyaoma/Desktop/Xjpynb/Data Files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['names/yob2000.txt',\n",
       " 'names/yob1938.txt',\n",
       " 'names/yob1910.txt',\n",
       " 'names/yob1904.txt',\n",
       " 'names/yob1905.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text files within names directory - glob\n",
    "name_files = glob.glob('names/*.txt') # unsorted by default\n",
    "name_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['names/yob2000.txt',\n",
       " 'names/yob2001.txt',\n",
       " 'names/yob2002.txt',\n",
       " 'names/yob2003.txt',\n",
       " 'names/yob2004.txt',\n",
       " 'names/yob2005.txt',\n",
       " 'names/yob2006.txt',\n",
       " 'names/yob2007.txt',\n",
       " 'names/yob2008.txt',\n",
       " 'names/yob2009.txt',\n",
       " 'names/yob2010.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text files within names directory - glob\n",
    "name_iter = glob.iglob('names/*.txt')\n",
    "sorted([f for f in name_iter if 'yob2' in f]) # use list comprehension to filter to 2000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard File Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers built-in functionality for reading from and writing to text files, which is useful for interacting with both structured and unstructured data. Everything that is read from or written to a file is a string, so you must using casting (e.g., cast numerical scalars using **str** to write to a file, cast strings to **int**, **float**, and **bool** when reading from a file) as needed.\n",
    "\n",
    "The basic syntax for interacting with file objects is:\n",
    "```\n",
    "f = open(fname, mode='r')\n",
    "```\n",
    "where *fname* is either a file name string ('data.txt') or a full path-to-file string ('~/Documents/data.txt') and *mode* is most commonly 'r' (read only), 'w' (write only), 'a' (append), or 'r+' (read and write). When writing to a new file, it's important to specify write mode so that the file has the appropriate permissions to write data to the file. It's also important to include the appropriate delimiter (if applicable) and the appropriate newline character for your respective operating system (see os.linesep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.linesep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **open** function creates a file object, which has many attributes and methods for interacting with the file. The most notable methods are:\n",
    "\n",
    "* f.read(*size*) - Reads entire file as a string (if *size* is not specified), or a chunk of the file (equal to *size* in bytes)\n",
    "* f.readline() - Generator that produces one line of the file at a time\n",
    "* Loop!\n",
    "```\n",
    "for line in f:\n",
    "    print(line)\n",
    "```\n",
    "* f.write(*s*) - Write string _s_ to file\n",
    "* f.close() - Close file when done reading/writing\n",
    "\n",
    "It's important to note that once you reach of the end of the file, you cannot iterate through it again, unless you re-open the file or navigate to a specific place in the file using f.seek(*offset*), where *offset* is the location in the file where you want to move, relative to the beginning of the file (0 bytes). You can also use f.tell() to determine the current location (in bytes) in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='names/yob2000.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open name file\n",
    "f = open(name_files[0]) # default is read only mode ('r')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emily,F,25949\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read line of file\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannah,F,23066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print next line of file\n",
    "print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check file position\n",
    "f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emily,F,25949\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go back to beginning of file\n",
    "f.seek(0)\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quinn', 'Quincy', 'Quiana', 'Queen', 'Quanisha', 'Quianna', 'Queenie', 'Qiana', 'Quinlan', 'Quiara', 'Quintasia', 'Quantaya', 'Quintessa', 'Quincey', 'Quyen', 'Quanesha', 'Quinci', 'Quinesha', 'Quinlyn', 'Qiara', 'Quincie', 'Quaneisha', 'Quasia', 'Quantasia', 'Quinisha', 'Quinteria', 'Quanique', 'Quierra', 'Quadasia', 'Quantavia', 'Quashia', 'Querida', 'Quintaya', 'Quynh', 'Quaniya', 'Quayla', 'Queena', 'Quetzalli', 'Qadira', 'Qianna', 'Quanae', 'Quetzali', 'Quiera', 'Quincee', 'Quinlin', 'Quinne', 'Quinnlyn', 'Quintara', 'Quintera', 'Quinterria', 'Quinn', 'Quentin', 'Quinton', 'Quincy', 'Quintin', 'Quinten', 'Quinlan', 'Quenton', 'Quran', 'Quadir', 'Quintavious', 'Quan', 'Quin', 'Quenten', 'Quincey', 'Quindarius', 'Qasim', 'Quest', 'Quade', 'Quamir', 'Quantavious', 'Quavon', 'Quadarius', 'Quantez', 'Quintez', 'Quaid', 'Quashawn', 'Quandarius', 'Quintyn', 'Quintan', 'Quang', 'Quante', 'Qadir', 'Quinnton', 'Quintarius', 'Quintrell', 'Quadre', 'Quashaun', 'Quantae', 'Quantavius', 'Quavion', 'Quintavius', 'Quamaine', 'Quron', 'Quartez', 'Quindarious', 'Quinterius', 'Quillan', 'Quaron', 'Quame', 'Quantavis', 'Quantrell', 'Quaylon', 'Quentyn', 'Quinlin', 'Quinnlan', 'Quoc', 'Quadrell', 'Qualin', 'Quantarius', 'Quashon', 'Quasim', 'Quason', 'Quendarius', 'Quentavious', 'Quevon', 'Quince', 'Quinshawn', 'Quintel', 'Quinterious', 'Quinterrius', 'Quishawn', 'Qamar', 'Qi', 'Quadarious', 'Quamere', 'Quashun', 'Qudarius', 'Que', 'Quess', 'Quienten', 'Quintavis', 'Quintell', 'Quion', 'Quisean', 'Qian', 'Quadere', 'Quameer', 'Quandre', 'Quantay', 'Quanterius', 'Quanterrious', 'Quatavious', 'Quayshawn', 'Quayvon', 'Quency', 'Quetzalcoatl', 'Quinell']\n"
     ]
    }
   ],
   "source": [
    "# Loop through file and extract all names that begin with a specific letter\n",
    "letter = 'Q'\n",
    "f.seek(0)\n",
    "names = []\n",
    "for line in f:\n",
    "    if line[0] == letter:\n",
    "        names.append(line.split(',')[0])\n",
    "f.close()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open new file to write results\n",
    "g = open(letter + 'names.csv', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through file and write names that begin with a specific letter, along with their length\n",
    "with open(name_files[0]) as f: # alternate construction for opening file, closes file upon exit from with statement\n",
    "    for line in f:\n",
    "        if line[0] == letter:\n",
    "            name = line.split(',')[0]\n",
    "            g.write(name + ',' + str(len(name)) + os.linesep)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinn,5\r\n",
      "Quincy,6\r\n",
      "Quiana,6\r\n",
      "Queen,5\r\n",
      "Quanisha,8\r\n",
      "Quianna,7\r\n",
      "Queenie,7\r\n",
      "Qiana,5\r\n",
      "Quinlan,7\r\n",
      "Quiara,6\r\n"
     ]
    }
   ],
   "source": [
    "# Preview file contents\n",
    "!head -n10 $g.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comma Separated Files (.csv) are one of the most common flat file formats for storing data, and are often output from common software platforms such as Microsoft Excel, various databases, or other programming languages. Commas are sufficient delimiters for structured numerical data (in the U.S.), but they can cause problems when working with data that may contain commas. In such cases, you should use another delimiter (e.g., space, tab; see csv.writer) that facilitates an easy import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary,F,7065\r",
      "\r\n",
      "Anna,F,2604\r",
      "\r\n",
      "Emma,F,2003\r",
      "\r\n",
      "Elizabeth,F,1939\r",
      "\r\n",
      "Minnie,F,1746\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 names/yob1880.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **csv** module facilitates easy reading and writing to/from .csv files. The csv has two primary functions, csv.reader and csv.writer, that perform these functions. Each of these functions must be fed an open file handle (i.e., generated via an open(*filename*) call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and create csv reader object\n",
    "f = open(name_files[0])\n",
    "reader = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unique', 'Uma', 'Ursula', 'Unknown', 'Uriah', 'Una', 'Ulyssa', 'Unity', 'Urvi', 'Ulani', 'Uchenna', 'Uniqua', 'Umayah', 'Uriel', 'Uyen', 'Uchechi', 'Uchechukwu', 'Ulyana', 'Unica', 'Ubah', 'Ugochi', 'Ula', 'Umaya', 'Urja', 'Urmi', 'Ushna', 'Uzma', 'Uriel', 'Ulises', 'Ulysses', 'Uriah', 'Ulisses', 'Umar', 'Uziel', 'Ulices', 'Ubaldo', 'Unknown', 'Unique', 'Ulyses', 'Usman', 'Usama', 'Uri', 'Usher', 'Uzziel', 'Umair', 'Umer', 'Urian', 'Usiel', 'Uchenna', 'Uday', 'Uzziah', 'Uvaldo', 'Uzair', 'Urias', 'Ugonna', 'Utah', 'Ulrich', 'Urbano', 'Uzoma', 'Ulisis', 'Ulysess', 'Umberto', 'Urban', 'Urijah', 'Urie', 'Usamah']\n"
     ]
    }
   ],
   "source": [
    "# Loop through file and extract all names that begin with a specific letter\n",
    "letter = 'U'\n",
    "names = []\n",
    "for line in reader:\n",
    "    if line[0][0] == letter:\n",
    "        names.append(line[0])\n",
    "f.close()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file for writing and create csv writer object\n",
    "g = open(letter + 'names.csv', 'w')\n",
    "writer = csv.writer(g, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through file and extract all names that begin with a specific letter, along with their length\n",
    "for name in names:\n",
    "    writer.writerow((name, len(name)))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique,6\r",
      "\r\n",
      "Uma,3\r",
      "\r\n",
      "Ursula,6\r",
      "\r\n",
      "Unknown,7\r",
      "\r\n",
      "Uriah,5\r",
      "\r\n",
      "Una,3\r",
      "\r\n",
      "Ulyssa,6\r",
      "\r\n",
      "Unity,5\r",
      "\r\n",
      "Urvi,4\r",
      "\r\n",
      "Ulani,5\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Preview file contents\n",
    "!head -n10 $g.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle and shelve Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to reading and writing data from/to files, you will also find it useful to directly save objects to a file, so that you can quickly load them without having to repeatedly convert them from text files. The pickle and shelve modules offer functionality for doing this:\n",
    "\n",
    "* The **pickle** module performs *object serialization*, through which a Python object is converted into a binary format that is saveable.\n",
    "\n",
    "* The **shelve** module performs *object persistence*, through which the object itself is preserved for later use in a dictionary-like structure (i.e., upon re-loading). The shelve module relies on the pickle module to save the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file in binary write mode for pickling\n",
    "f = open('name_list','bw') # pickle files do not need a file extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump list of names to file and close file\n",
    "pickle.dump(names, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unique', 'Uma', 'Ursula', 'Unknown', 'Uriah', 'Una', 'Ulyssa', 'Unity', 'Urvi', 'Ulani', 'Uchenna', 'Uniqua', 'Umayah', 'Uriel', 'Uyen', 'Uchechi', 'Uchechukwu', 'Ulyana', 'Unica', 'Ubah', 'Ugochi', 'Ula', 'Umaya', 'Urja', 'Urmi', 'Ushna', 'Uzma', 'Uriel', 'Ulises', 'Ulysses', 'Uriah', 'Ulisses', 'Umar', 'Uziel', 'Ulices', 'Ubaldo', 'Unknown', 'Unique', 'Ulyses', 'Usman', 'Usama', 'Uri', 'Usher', 'Uzziel', 'Umair', 'Umer', 'Urian', 'Usiel', 'Uchenna', 'Uday', 'Uzziah', 'Uvaldo', 'Uzair', 'Urias', 'Ugonna', 'Utah', 'Ulrich', 'Urbano', 'Uzoma', 'Ulisis', 'Ulysess', 'Umberto', 'Urban', 'Urijah', 'Urie', 'Usamah']\n"
     ]
    }
   ],
   "source": [
    "# Delete names and re-load from pickle file\n",
    "del names\n",
    "f = open('name_list','br')\n",
    "names = pickle.load(f)\n",
    "f.close()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shelve.DbfilenameShelf at 0x1123350b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open shelve file for object persistence\n",
    "S = shelve.open('names_shelve') # or, with shelve.open('names_shelve') as S:\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add list of names to S and close file\n",
    "S['names'] = names\n",
    "S.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unique', 'Uma', 'Ursula', 'Unknown', 'Uriah', 'Una', 'Ulyssa', 'Unity', 'Urvi', 'Ulani', 'Uchenna', 'Uniqua', 'Umayah', 'Uriel', 'Uyen', 'Uchechi', 'Uchechukwu', 'Ulyana', 'Unica', 'Ubah', 'Ugochi', 'Ula', 'Umaya', 'Urja', 'Urmi', 'Ushna', 'Uzma', 'Uriel', 'Ulises', 'Ulysses', 'Uriah', 'Ulisses', 'Umar', 'Uziel', 'Ulices', 'Ubaldo', 'Unknown', 'Unique', 'Ulyses', 'Usman', 'Usama', 'Uri', 'Usher', 'Uzziel', 'Umair', 'Umer', 'Urian', 'Usiel', 'Uchenna', 'Uday', 'Uzziah', 'Uvaldo', 'Uzair', 'Urias', 'Ugonna', 'Utah', 'Ulrich', 'Urbano', 'Uzoma', 'Ulisis', 'Ulysess', 'Umberto', 'Urban', 'Urijah', 'Urie', 'Usamah']\n"
     ]
    }
   ],
   "source": [
    "# Delete list of names and re-load from shelve file\n",
    "del names\n",
    "with shelve.open('names_shelve') as S:\n",
    "    print(S['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being the primary module for data processing and analysis, it should not surprise you that there is a lot of functionality for interacting with various types of data sources. This functionality has grown significantly over the years, and will continue to grow as new file formats emerge.\n",
    "\n",
    "* pd.read_csv - Load delimited data from a file, URL, or file-like object\n",
    "* pd.read_table - Load delimited data from a file, URL, or file-like object\n",
    "* pd.read_fwf - Load data in fixed-width column format (non-delimited files)\n",
    "* pd.read_clipboard - Load data that is copied directly from another source (e.g., web page, Excel)\n",
    "* pd.read_excel - Load data directly from Excel file (without saving to .csv)\n",
    "* pd.read_html - Read tables found on a web page (URL) or within an HTML document\n",
    "* pd.read_json - Read data from a JSON (JavaScript Object Notation) file\n",
    "* pd.read_pickle - Read an objected stored in Python pickle format\n",
    "* pd.read_sas - Read a SAS dataset\n",
    "* pd.read_sql - Read the results of an SQL query into a DataFrame\n",
    "* pd.read_stata - Read a dataset from Stata file format\n",
    "\n",
    "And more! See Table 6-1 in the text for additional functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Text Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv is the most common functions use to import data from text (flat) files. As there are many potential nuances to loading data from text files, there are many arguments to this function that can facilitate proper data loading (in addition to the file path/name):\n",
    "\n",
    "* sep, delimiter - String or regular expression to use to split the columns in each row\n",
    "* header - Row number to use as column names, use header=None if there is no header in the data\n",
    "* index_col - Column number(s) to use as index; multiple columns indicates hierarchical indexing\n",
    "* names - Sequence of column names for result, use with header=None\n",
    "* na_values - Sequence of values to replace with NA\n",
    "* parse_dates - Boolean to determine whether to attempt to parse data to datetime scalars; False by default\n",
    "* converters - Dictionary that specifies functions (values) to apply to specific columns (keys)\n",
    "* squeeze - Boolean that, if True, will convert DataFrame to Series if there is only one column\n",
    "\n",
    "In addition, there are several arguments that allow you read text files in pieces:\n",
    "\n",
    "* nrows - Number of rows to read from beginning of file\n",
    "* skiprows - Number of rows at beginning of file to ignore or list of specific row numbers to skip\n",
    "* skip_footer - Number of rows to ignore at end of file\n",
    "* chunksize - Creates iterator for looping through file in pieces; convenient for working with large files\n",
    "\n",
    "And more! See Table 6-2 in the text for additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lead Studio</th>\n",
       "      <th>Audience  score %</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Rotten Tomatoes %</th>\n",
       "      <th>Worldwide Gross</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27 Dresses</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>71</td>\n",
       "      <td>5.343622</td>\n",
       "      <td>40</td>\n",
       "      <td>160.308654</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(500) Days of Summer</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>81</td>\n",
       "      <td>8.096000</td>\n",
       "      <td>87</td>\n",
       "      <td>60.720000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Dangerous Method</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Independent</td>\n",
       "      <td>89</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>79</td>\n",
       "      <td>8.972895</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Serious Man</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Universal</td>\n",
       "      <td>64</td>\n",
       "      <td>4.382857</td>\n",
       "      <td>89</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Across the Universe</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Independent</td>\n",
       "      <td>84</td>\n",
       "      <td>0.652603</td>\n",
       "      <td>54</td>\n",
       "      <td>29.367143</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Film    Genre  Lead Studio  Audience  score %  \\\n",
       "0            27 Dresses   Comedy          Fox                 71   \n",
       "1  (500) Days of Summer   Comedy          Fox                 81   \n",
       "2    A Dangerous Method    Drama  Independent                 89   \n",
       "3         A Serious Man    Drama    Universal                 64   \n",
       "4   Across the Universe  Romance  Independent                 84   \n",
       "\n",
       "   Profitability  Rotten Tomatoes %  Worldwide Gross  Year  \n",
       "0       5.343622                 40       160.308654  2008  \n",
       "1       8.096000                 87        60.720000  2009  \n",
       "2       0.448645                 79         8.972895  2011  \n",
       "3       4.382857                 89        30.680000  2009  \n",
       "4       0.652603                 54        29.367143  2007  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movies data using pd.read_csv\n",
    "df = pd.read_csv('movies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Film                  object\n",
       "Genre                 object\n",
       "Lead Studio           object\n",
       "Audience  score %      int64\n",
       "Profitability        float64\n",
       "Rotten Tomatoes %      int64\n",
       "Worldwide Gross      float64\n",
       "Year                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Film', 'Genre', 'Lead Studio', 'Audience  score %', 'Profitability',\n",
       "       'Rotten Tomatoes %', 'Worldwide Gross', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lead Studio</th>\n",
       "      <th>Audience  score %</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Rotten Tomatoes %</th>\n",
       "      <th>Worldwide Gross</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27 Dresses</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.343622</td>\n",
       "      <td>40.0</td>\n",
       "      <td>160.308654</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(500) Days of Summer</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.096000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>60.720000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Dangerous Method</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Independent</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>79.0</td>\n",
       "      <td>8.972895</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Serious Man</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Universal</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.382857</td>\n",
       "      <td>89.0</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Across the Universe</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Independent</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.652603</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.367143</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Film    Genre  Lead Studio  Audience  score %  \\\n",
       "0            27 Dresses   Comedy          Fox               71.0   \n",
       "1  (500) Days of Summer   Comedy          Fox               81.0   \n",
       "2    A Dangerous Method    Drama  Independent               89.0   \n",
       "3         A Serious Man    Drama    Universal               64.0   \n",
       "4   Across the Universe  Romance  Independent               84.0   \n",
       "\n",
       "   Profitability  Rotten Tomatoes %  Worldwide Gross  Year  \n",
       "0       5.343622               40.0       160.308654  2008  \n",
       "1       8.096000               87.0        60.720000  2009  \n",
       "2       0.448645               79.0         8.972895  2011  \n",
       "3       4.382857               89.0        30.680000  2009  \n",
       "4       0.652603               54.0        29.367143  2007  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movies data with dtype specifications\n",
    "df = pd.read_csv('movies.csv', dtype={'Audience  score %': np.float64, 'Rotten Tomatoes %': np.float64})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emily</th>\n",
       "      <th>F</th>\n",
       "      <th>25949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madison</td>\n",
       "      <td>F</td>\n",
       "      <td>19965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexis</td>\n",
       "      <td>F</td>\n",
       "      <td>17622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emily  F  25949\n",
       "0   Hannah  F  23066\n",
       "1  Madison  F  19965\n",
       "2   Ashley  F  17991\n",
       "3    Sarah  F  17677\n",
       "4   Alexis  F  17622"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data without headers\n",
    "df = pd.read_csv(name_files[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emily</td>\n",
       "      <td>F</td>\n",
       "      <td>25949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madison</td>\n",
       "      <td>F</td>\n",
       "      <td>19965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2\n",
       "0    Emily  F  25949\n",
       "1   Hannah  F  23066\n",
       "2  Madison  F  19965\n",
       "3   Ashley  F  17991\n",
       "4    Sarah  F  17677"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data without headers\n",
    "df = pd.read_csv(name_files[0], header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emily</td>\n",
       "      <td>F</td>\n",
       "      <td>25949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madison</td>\n",
       "      <td>F</td>\n",
       "      <td>19965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Gender  Count\n",
       "0    Emily      F  25949\n",
       "1   Hannah      F  23066\n",
       "2  Madison      F  19965\n",
       "3   Ashley      F  17991\n",
       "4    Sarah      F  17677"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data without headers\n",
    "df = pd.read_csv(name_files[0], header=None, names=['Name','Gender','Count'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Tabular Data from the Web with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping tabular data from a web site (or raw HTML) is probably the next most common method for importing data into your Python workspace. In addition to pd.read_clipboard--which you may find useful for simple tables--the pd.read_html function is the standard pandas function for scraping tabular data from a website. This function takes in a URL (as a string), HTML file-like object, or raw HTML text (as a string), and returns a list of all found HTML tables.\n",
    "\n",
    "In addition to several of the same arguments that are available for the pd.read_csv function (e.g., header, index_col, skiprows, parse_dates, na_values, converters), there is also a *match* argument for which you can specify the exact table(s) that you want to return. The *match* argument could be an explicit string (e.g., substring, word, phrase) that you want to match (anywhere) within the table, or a regular expression (later).\n",
    "\n",
    "**Also, be warned, scraping data from a web site is a messy process! Oftentimes, we will need to perform significant processing on the data before it is ready for analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>2018</th>\n",
       "      <th>Last 3</th>\n",
       "      <th>Last 1</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>118.2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.9</td>\n",
       "      <td>116.5</td>\n",
       "      <td>106.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golden State</td>\n",
       "      <td>118.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>117.6</td>\n",
       "      <td>112.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>115.5</td>\n",
       "      <td>129.3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>112.6</td>\n",
       "      <td>109.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>115.4</td>\n",
       "      <td>120.7</td>\n",
       "      <td>103.0</td>\n",
       "      <td>115.1</td>\n",
       "      <td>115.8</td>\n",
       "      <td>111.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>115.1</td>\n",
       "      <td>114.7</td>\n",
       "      <td>105.0</td>\n",
       "      <td>117.6</td>\n",
       "      <td>112.7</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Portland</td>\n",
       "      <td>114.4</td>\n",
       "      <td>108.7</td>\n",
       "      <td>108.0</td>\n",
       "      <td>117.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>105.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>114.2</td>\n",
       "      <td>119.3</td>\n",
       "      <td>131.0</td>\n",
       "      <td>114.9</td>\n",
       "      <td>113.4</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Okla City</td>\n",
       "      <td>114.1</td>\n",
       "      <td>104.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>113.6</td>\n",
       "      <td>107.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>114.0</td>\n",
       "      <td>103.3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>114.7</td>\n",
       "      <td>113.4</td>\n",
       "      <td>111.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Washington</td>\n",
       "      <td>114.0</td>\n",
       "      <td>110.7</td>\n",
       "      <td>110.0</td>\n",
       "      <td>116.8</td>\n",
       "      <td>111.4</td>\n",
       "      <td>106.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Houston</td>\n",
       "      <td>113.9</td>\n",
       "      <td>114.7</td>\n",
       "      <td>104.0</td>\n",
       "      <td>116.9</td>\n",
       "      <td>110.9</td>\n",
       "      <td>111.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>113.3</td>\n",
       "      <td>118.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>115.8</td>\n",
       "      <td>110.9</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>112.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>110.3</td>\n",
       "      <td>109.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>112.3</td>\n",
       "      <td>115.3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>113.7</td>\n",
       "      <td>111.0</td>\n",
       "      <td>106.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Boston</td>\n",
       "      <td>111.8</td>\n",
       "      <td>95.7</td>\n",
       "      <td>104.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LA Lakers</td>\n",
       "      <td>111.8</td>\n",
       "      <td>112.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>112.5</td>\n",
       "      <td>108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>111.4</td>\n",
       "      <td>108.7</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.7</td>\n",
       "      <td>110.2</td>\n",
       "      <td>102.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Utah</td>\n",
       "      <td>111.2</td>\n",
       "      <td>96.3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>112.4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>103.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>110.7</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>113.1</td>\n",
       "      <td>108.3</td>\n",
       "      <td>108.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denver</td>\n",
       "      <td>110.6</td>\n",
       "      <td>113.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>113.7</td>\n",
       "      <td>107.5</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>108.9</td>\n",
       "      <td>114.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>107.4</td>\n",
       "      <td>102.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>107.5</td>\n",
       "      <td>118.3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>107.6</td>\n",
       "      <td>107.4</td>\n",
       "      <td>103.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>107.3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>108.4</td>\n",
       "      <td>106.2</td>\n",
       "      <td>105.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>106.8</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>109.6</td>\n",
       "      <td>104.4</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>106.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>108.5</td>\n",
       "      <td>104.8</td>\n",
       "      <td>103.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Miami</td>\n",
       "      <td>105.7</td>\n",
       "      <td>108.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>105.4</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>104.9</td>\n",
       "      <td>97.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>103.6</td>\n",
       "      <td>106.3</td>\n",
       "      <td>102.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New York</td>\n",
       "      <td>104.6</td>\n",
       "      <td>99.3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.9</td>\n",
       "      <td>103.2</td>\n",
       "      <td>104.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>104.5</td>\n",
       "      <td>100.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>105.2</td>\n",
       "      <td>103.8</td>\n",
       "      <td>108.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Memphis</td>\n",
       "      <td>103.5</td>\n",
       "      <td>117.3</td>\n",
       "      <td>132.0</td>\n",
       "      <td>104.6</td>\n",
       "      <td>102.5</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team   2018  Last 3  Last 1   Home   Away   2017\n",
       "Rank                                                          \n",
       "1        Milwaukee  118.2   120.0   119.0  119.9  116.5  106.1\n",
       "2     Golden State  118.0   128.0   132.0  118.5  117.6  112.8\n",
       "3     Philadelphia  115.5   129.3   112.0  118.5  112.6  109.7\n",
       "4      New Orleans  115.4   120.7   103.0  115.1  115.8  111.5\n",
       "5      LA Clippers  115.1   114.7   105.0  117.6  112.7  109.0\n",
       "6         Portland  114.4   108.7   108.0  117.8  111.0  105.6\n",
       "7       Sacramento  114.2   119.3   131.0  114.9  113.4   98.8\n",
       "8        Okla City  114.1   104.3   120.0  114.6  113.6  107.4\n",
       "9          Toronto  114.0   103.3    98.0  114.7  113.4  111.2\n",
       "10      Washington  114.0   110.7   110.0  116.8  111.4  106.6\n",
       "11         Houston  113.9   114.7   104.0  116.9  110.9  111.1\n",
       "12         Atlanta  113.3   118.0   134.0  115.8  110.9  103.4\n",
       "13       Minnesota  112.5   107.0    95.0  114.6  110.3  109.1\n",
       "14        Brooklyn  112.3   115.3   108.0  113.7  111.0  106.6\n",
       "15          Boston  111.8    95.7   104.0  113.0  110.5  103.5\n",
       "16       LA Lakers  111.8   112.0   101.0  111.0  112.5  108.1\n",
       "17     San Antonio  111.4   108.7   103.0  112.7  110.2  102.4\n",
       "18            Utah  111.2    96.3   101.0  112.4  110.0  103.9\n",
       "19       Charlotte  110.7   114.0   114.0  113.1  108.3  108.2\n",
       "20          Denver  110.6   113.0   117.0  113.7  107.5  110.0\n",
       "21          Dallas  108.9   114.3    94.0  110.3  107.4  102.3\n",
       "22         Phoenix  107.5   118.3   109.0  107.6  107.4  103.9\n",
       "23         Indiana  107.3    87.0    96.0  108.4  106.2  105.2\n",
       "24         Orlando  106.8    93.0    93.0  109.6  104.4  103.4\n",
       "25         Detroit  106.7    96.0   103.0  108.5  104.8  103.8\n",
       "26           Miami  105.7   108.3    94.0  106.0  105.4  103.4\n",
       "27         Chicago  104.9    97.0   109.0  103.6  106.3  102.9\n",
       "28        New York  104.6    99.3    89.0  105.9  103.2  104.5\n",
       "29       Cleveland  104.5   100.3    97.0  105.2  103.8  108.8\n",
       "30         Memphis  103.5   117.3   132.0  104.6  102.5   99.3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean HTML table\n",
    "url = 'https://www.teamrankings.com/nba/stat/points-per-game'\n",
    "df = pd.read_html(url, index_col=0)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team      Washington\n",
       "2018             114\n",
       "Last 3         110.7\n",
       "Last 1           110\n",
       "Home           116.8\n",
       "Away           111.4\n",
       "2017           106.6\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index specific ranked team\n",
    "df.loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[          Eastern Conference   W   L   W/L%    GB   PS/G   PA/G   SRS\n",
       " 0       Toronto Raptors*(1)  59  23  0.720       111.7  103.9  7.29\n",
       " 1        Boston Celtics*(2)  55  27  0.671   4.0  104.0  100.4  3.23\n",
       " 2    Philadelphia 76ers*(3)  52  30  0.634   7.0  109.8  105.3  4.30\n",
       " 3   Cleveland Cavaliers*(4)  50  32  0.610   9.0  110.9  109.9  0.59\n",
       " 4        Indiana Pacers*(5)  48  34  0.585  11.0  105.6  104.2  1.18\n",
       " 5            Miami Heat*(6)  44  38  0.537  15.0  103.4  102.9  0.15\n",
       " 6       Milwaukee Bucks*(7)  44  38  0.537  15.0  106.5  106.8 -0.45\n",
       " 7    Washington Wizards*(8)  43  39  0.524  16.0  106.6  106.0  0.53\n",
       " 8        Detroit Pistons(9)  39  43  0.476  20.0  103.8  103.9 -0.26\n",
       " 9     Charlotte Hornets(10)  36  46  0.439  23.0  108.2  108.0  0.07\n",
       " 10      New York Knicks(11)  29  53  0.354  30.0  104.5  108.0 -3.53\n",
       " 11        Brooklyn Nets(12)  28  54  0.341  31.0  106.6  110.3 -3.67\n",
       " 12        Chicago Bulls(13)  27  55  0.329  32.0  102.9  110.0 -6.84\n",
       " 13        Orlando Magic(14)  25  57  0.305  34.0  103.4  108.2 -4.92\n",
       " 14        Atlanta Hawks(15)  24  58  0.293  35.0  103.4  108.8 -5.30,\n",
       "              Western Conference   W   L   W/L%    GB   PS/G   PA/G   SRS\n",
       " 0          Houston Rockets*(1)  65  17  0.793       112.4  103.9  8.21\n",
       " 1    Golden State Warriors*(2)  58  24  0.707   7.0  113.5  107.5  5.79\n",
       " 2   Portland Trail Blazers*(3)  49  33  0.598  16.0  105.6  103.0  2.60\n",
       " 3    Oklahoma City Thunder*(4)  48  34  0.585  17.0  107.9  104.4  3.42\n",
       " 4                Utah Jazz*(5)  48  34  0.585  17.0  104.1   99.8  4.47\n",
       " 5     New Orleans Pelicans*(6)  48  34  0.585  17.0  111.7  110.4  1.48\n",
       " 6        San Antonio Spurs*(7)  47  35  0.573  18.0  102.7   99.8  2.89\n",
       " 7   Minnesota Timberwolves*(8)  47  35  0.573  18.0  109.5  107.3  2.35\n",
       " 8            Denver Nuggets(9)  46  36  0.561  19.0  110.0  108.5  1.57\n",
       " 9     Los Angeles Clippers(10)  42  40  0.512  23.0  109.0  109.0  0.15\n",
       " 10      Los Angeles Lakers(11)  35  47  0.427  30.0  108.1  109.6 -1.44\n",
       " 11        Sacramento Kings(12)  27  55  0.329  38.0   98.8  105.8 -6.60\n",
       " 12        Dallas Mavericks(13)  24  58  0.293  41.0  102.3  105.4 -2.70\n",
       " 13       Memphis Grizzlies(14)  22  60  0.268  43.0   99.3  105.5 -5.81\n",
       " 14            Phoenix Suns(15)  21  61  0.256  44.0  103.9  113.3 -8.80,\n",
       "           Eastern Conference                   W                   L  \\\n",
       " 0          Atlantic Division   Atlantic Division   Atlantic Division   \n",
       " 1       Toronto Raptors*(1)                  59                  23   \n",
       " 2        Boston Celtics*(2)                  55                  27   \n",
       " 3    Philadelphia 76ers*(3)                  52                  30   \n",
       " 4       New York Knicks(11)                  29                  53   \n",
       " 5         Brooklyn Nets(12)                  28                  54   \n",
       " 6           Central Division    Central Division    Central Division   \n",
       " 7   Cleveland Cavaliers*(4)                  50                  32   \n",
       " 8        Indiana Pacers*(5)                  48                  34   \n",
       " 9       Milwaukee Bucks*(7)                  44                  38   \n",
       " 10       Detroit Pistons(9)                  39                  43   \n",
       " 11        Chicago Bulls(13)                  27                  55   \n",
       " 12        Southeast Division  Southeast Division  Southeast Division   \n",
       " 13           Miami Heat*(6)                  44                  38   \n",
       " 14   Washington Wizards*(8)                  43                  39   \n",
       " 15    Charlotte Hornets(10)                  36                  46   \n",
       " 16        Orlando Magic(14)                  25                  57   \n",
       " 17        Atlanta Hawks(15)                  24                  58   \n",
       " \n",
       "                   W/L%                  GB                PS/G  \\\n",
       " 0    Atlantic Division   Atlantic Division   Atlantic Division   \n",
       " 1                 .720                                  111.7   \n",
       " 2                 .671                 4.0               104.0   \n",
       " 3                 .634                 7.0               109.8   \n",
       " 4                 .354                30.0               104.5   \n",
       " 5                 .341                31.0               106.6   \n",
       " 6     Central Division    Central Division    Central Division   \n",
       " 7                 .610                                  110.9   \n",
       " 8                 .585                 2.0               105.6   \n",
       " 9                 .537                 6.0               106.5   \n",
       " 10                .476                11.0               103.8   \n",
       " 11                .329                23.0               102.9   \n",
       " 12  Southeast Division  Southeast Division  Southeast Division   \n",
       " 13                .537                                  103.4   \n",
       " 14                .524                 1.0               106.6   \n",
       " 15                .439                 8.0               108.2   \n",
       " 16                .305                19.0               103.4   \n",
       " 17                .293                20.0               103.4   \n",
       " \n",
       "                   PA/G                 SRS  \n",
       " 0    Atlantic Division   Atlantic Division  \n",
       " 1                103.9                7.29  \n",
       " 2                100.4                3.23  \n",
       " 3                105.3                4.30  \n",
       " 4                108.0               -3.53  \n",
       " 5                110.3               -3.67  \n",
       " 6     Central Division    Central Division  \n",
       " 7                109.9                0.59  \n",
       " 8                104.2                1.18  \n",
       " 9                106.8               -0.45  \n",
       " 10               103.9               -0.26  \n",
       " 11               110.0               -6.84  \n",
       " 12  Southeast Division  Southeast Division  \n",
       " 13               102.9                0.15  \n",
       " 14               106.0                0.53  \n",
       " 15               108.0                0.07  \n",
       " 16               108.2               -4.92  \n",
       " 17               108.8               -5.30  ,\n",
       "              Western Conference                   W                   L  \\\n",
       " 0            Northwest Division  Northwest Division  Northwest Division   \n",
       " 1   Portland Trail Blazers*(3)                  49                  33   \n",
       " 2    Oklahoma City Thunder*(4)                  48                  34   \n",
       " 3                Utah Jazz*(5)                  48                  34   \n",
       " 4   Minnesota Timberwolves*(8)                  47                  35   \n",
       " 5            Denver Nuggets(9)                  46                  36   \n",
       " 6              Pacific Division    Pacific Division    Pacific Division   \n",
       " 7    Golden State Warriors*(2)                  58                  24   \n",
       " 8     Los Angeles Clippers(10)                  42                  40   \n",
       " 9       Los Angeles Lakers(11)                  35                  47   \n",
       " 10        Sacramento Kings(12)                  27                  55   \n",
       " 11            Phoenix Suns(15)                  21                  61   \n",
       " 12           Southwest Division  Southwest Division  Southwest Division   \n",
       " 13         Houston Rockets*(1)                  65                  17   \n",
       " 14    New Orleans Pelicans*(6)                  48                  34   \n",
       " 15       San Antonio Spurs*(7)                  47                  35   \n",
       " 16        Dallas Mavericks(13)                  24                  58   \n",
       " 17       Memphis Grizzlies(14)                  22                  60   \n",
       " \n",
       "                   W/L%                  GB                PS/G  \\\n",
       " 0   Northwest Division  Northwest Division  Northwest Division   \n",
       " 1                 .598                                  105.6   \n",
       " 2                 .585                 1.0               107.9   \n",
       " 3                 .585                 1.0               104.1   \n",
       " 4                 .573                 2.0               109.5   \n",
       " 5                 .561                 3.0               110.0   \n",
       " 6     Pacific Division    Pacific Division    Pacific Division   \n",
       " 7                 .707                                  113.5   \n",
       " 8                 .512                16.0               109.0   \n",
       " 9                 .427                23.0               108.1   \n",
       " 10                .329                31.0                98.8   \n",
       " 11                .256                37.0               103.9   \n",
       " 12  Southwest Division  Southwest Division  Southwest Division   \n",
       " 13                .793                                  112.4   \n",
       " 14                .585                17.0               111.7   \n",
       " 15                .573                18.0               102.7   \n",
       " 16                .293                41.0               102.3   \n",
       " 17                .268                43.0                99.3   \n",
       " \n",
       "                   PA/G                 SRS  \n",
       " 0   Northwest Division  Northwest Division  \n",
       " 1                103.0                2.60  \n",
       " 2                104.4                3.42  \n",
       " 3                 99.8                4.47  \n",
       " 4                107.3                2.35  \n",
       " 5                108.5                1.57  \n",
       " 6     Pacific Division    Pacific Division  \n",
       " 7                107.5                5.79  \n",
       " 8                109.0                0.15  \n",
       " 9                109.6               -1.44  \n",
       " 10               105.8               -6.60  \n",
       " 11               113.3               -8.80  \n",
       " 12  Southwest Division  Southwest Division  \n",
       " 13               103.9                8.21  \n",
       " 14               110.4                1.48  \n",
       " 15                99.8                2.89  \n",
       " 16               105.4               -2.70  \n",
       " 17               105.5               -5.81  ]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple HTML tables\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_2018.html'\n",
    "dfs = pd.read_html(url, match='Conference')\n",
    "len(dfs)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eastern Conference</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W/L%</th>\n",
       "      <th>GB</th>\n",
       "      <th>PS/G</th>\n",
       "      <th>PA/G</th>\n",
       "      <th>SRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toronto Raptors*(1)</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>.720</td>\n",
       "      <td></td>\n",
       "      <td>111.7</td>\n",
       "      <td>103.9</td>\n",
       "      <td>7.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston Celtics*(2)</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>.671</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philadelphia 76ers*(3)</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>.634</td>\n",
       "      <td>7.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>105.3</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Knicks(11)</td>\n",
       "      <td>29</td>\n",
       "      <td>53</td>\n",
       "      <td>.354</td>\n",
       "      <td>30.0</td>\n",
       "      <td>104.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brooklyn Nets(12)</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>.341</td>\n",
       "      <td>31.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>110.3</td>\n",
       "      <td>-3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cleveland Cavaliers*(4)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>.610</td>\n",
       "      <td></td>\n",
       "      <td>110.9</td>\n",
       "      <td>109.9</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indiana Pacers*(5)</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>.585</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.6</td>\n",
       "      <td>104.2</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Milwaukee Bucks*(7)</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>.537</td>\n",
       "      <td>6.0</td>\n",
       "      <td>106.5</td>\n",
       "      <td>106.8</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Detroit Pistons(9)</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>.476</td>\n",
       "      <td>11.0</td>\n",
       "      <td>103.8</td>\n",
       "      <td>103.9</td>\n",
       "      <td>-0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chicago Bulls(13)</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>.329</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.9</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Miami Heat*(6)</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>.537</td>\n",
       "      <td></td>\n",
       "      <td>103.4</td>\n",
       "      <td>102.9</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Washington Wizards*(8)</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>.524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Charlotte Hornets(10)</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>.439</td>\n",
       "      <td>8.0</td>\n",
       "      <td>108.2</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Orlando Magic(14)</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "      <td>.305</td>\n",
       "      <td>19.0</td>\n",
       "      <td>103.4</td>\n",
       "      <td>108.2</td>\n",
       "      <td>-4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Atlanta Hawks(15)</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>.293</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.4</td>\n",
       "      <td>108.8</td>\n",
       "      <td>-5.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Eastern Conference                   W                   L  \\\n",
       "0          Atlantic Division   Atlantic Division   Atlantic Division   \n",
       "1       Toronto Raptors*(1)                  59                  23   \n",
       "2        Boston Celtics*(2)                  55                  27   \n",
       "3    Philadelphia 76ers*(3)                  52                  30   \n",
       "4       New York Knicks(11)                  29                  53   \n",
       "5         Brooklyn Nets(12)                  28                  54   \n",
       "6           Central Division    Central Division    Central Division   \n",
       "7   Cleveland Cavaliers*(4)                  50                  32   \n",
       "8        Indiana Pacers*(5)                  48                  34   \n",
       "9       Milwaukee Bucks*(7)                  44                  38   \n",
       "10       Detroit Pistons(9)                  39                  43   \n",
       "11        Chicago Bulls(13)                  27                  55   \n",
       "12        Southeast Division  Southeast Division  Southeast Division   \n",
       "13           Miami Heat*(6)                  44                  38   \n",
       "14   Washington Wizards*(8)                  43                  39   \n",
       "15    Charlotte Hornets(10)                  36                  46   \n",
       "16        Orlando Magic(14)                  25                  57   \n",
       "17        Atlanta Hawks(15)                  24                  58   \n",
       "\n",
       "                  W/L%                  GB                PS/G  \\\n",
       "0    Atlantic Division   Atlantic Division   Atlantic Division   \n",
       "1                 .720                                  111.7   \n",
       "2                 .671                 4.0               104.0   \n",
       "3                 .634                 7.0               109.8   \n",
       "4                 .354                30.0               104.5   \n",
       "5                 .341                31.0               106.6   \n",
       "6     Central Division    Central Division    Central Division   \n",
       "7                 .610                                  110.9   \n",
       "8                 .585                 2.0               105.6   \n",
       "9                 .537                 6.0               106.5   \n",
       "10                .476                11.0               103.8   \n",
       "11                .329                23.0               102.9   \n",
       "12  Southeast Division  Southeast Division  Southeast Division   \n",
       "13                .537                                  103.4   \n",
       "14                .524                 1.0               106.6   \n",
       "15                .439                 8.0               108.2   \n",
       "16                .305                19.0               103.4   \n",
       "17                .293                20.0               103.4   \n",
       "\n",
       "                  PA/G                 SRS  \n",
       "0    Atlantic Division   Atlantic Division  \n",
       "1                103.9                7.29  \n",
       "2                100.4                3.23  \n",
       "3                105.3                4.30  \n",
       "4                108.0               -3.53  \n",
       "5                110.3               -3.67  \n",
       "6     Central Division    Central Division  \n",
       "7                109.9                0.59  \n",
       "8                104.2                1.18  \n",
       "9                106.8               -0.45  \n",
       "10               103.9               -0.26  \n",
       "11               110.0               -6.84  \n",
       "12  Southeast Division  Southeast Division  \n",
       "13               102.9                0.15  \n",
       "14               106.0                0.53  \n",
       "15               108.0                0.07  \n",
       "16               108.2               -4.92  \n",
       "17               108.8               -5.30  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show specific table\n",
    "dfs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data from pandas data structures to a file is very straightforward. There are corresponding pandas functions to output Series and DataFrame objects to most of the file types that have read functions. A summary table is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format Type</th>\n",
       "      <th>Data Description</th>\n",
       "      <th>Reader</th>\n",
       "      <th>Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>CSV</td>\n",
       "      <td>read_csv</td>\n",
       "      <td>to_csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "      <td>JSON</td>\n",
       "      <td>read_json</td>\n",
       "      <td>to_json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "      <td>HTML</td>\n",
       "      <td>read_html</td>\n",
       "      <td>to_html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text</td>\n",
       "      <td>Local clipboard</td>\n",
       "      <td>read_clipboard</td>\n",
       "      <td>to_clipboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binary</td>\n",
       "      <td>MS Excel</td>\n",
       "      <td>read_excel</td>\n",
       "      <td>to_excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>binary</td>\n",
       "      <td>HDF5 Format</td>\n",
       "      <td>read_hdf</td>\n",
       "      <td>to_hdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>binary</td>\n",
       "      <td>Feather Format</td>\n",
       "      <td>read_feather</td>\n",
       "      <td>to_feather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>binary</td>\n",
       "      <td>Parquet Format</td>\n",
       "      <td>read_parquet</td>\n",
       "      <td>to_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>binary</td>\n",
       "      <td>Msgpack</td>\n",
       "      <td>read_msgpack</td>\n",
       "      <td>to_msgpack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>binary</td>\n",
       "      <td>Stata</td>\n",
       "      <td>read_stata</td>\n",
       "      <td>to_stata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>binary</td>\n",
       "      <td>SAS</td>\n",
       "      <td>read_sas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>binary</td>\n",
       "      <td>Python Pickle Format</td>\n",
       "      <td>read_pickle</td>\n",
       "      <td>to_pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SQL</td>\n",
       "      <td>SQL</td>\n",
       "      <td>read_sql</td>\n",
       "      <td>to_sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SQL</td>\n",
       "      <td>Google Big Query</td>\n",
       "      <td>read_gbq</td>\n",
       "      <td>to_gbq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Format Type      Data Description          Reader        Writer\n",
       "0         text                   CSV        read_csv        to_csv\n",
       "1         text                  JSON       read_json       to_json\n",
       "2         text                  HTML       read_html       to_html\n",
       "3         text       Local clipboard  read_clipboard  to_clipboard\n",
       "4       binary              MS Excel      read_excel      to_excel\n",
       "5       binary           HDF5 Format        read_hdf        to_hdf\n",
       "6       binary        Feather Format    read_feather    to_feather\n",
       "7       binary        Parquet Format    read_parquet    to_parquet\n",
       "8       binary               Msgpack    read_msgpack    to_msgpack\n",
       "9       binary                 Stata      read_stata      to_stata\n",
       "10      binary                   SAS        read_sas           NaN\n",
       "11      binary  Python Pickle Format     read_pickle     to_pickle\n",
       "12         SQL                   SQL        read_sql        to_sql\n",
       "13         SQL      Google Big Query        read_gbq        to_gbq"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html('https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file type has its own distinct set of arguments that allow you to configure how the data is saved to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output NBA team scoring data to .csv file\n",
    "df.to_csv('nba_scoring2019.csv', columns=['Team','2018','Home','Away'], header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Time: pandas Lab"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
